import pandas as pd
import ollama

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from collections import Counter

"""
í”„ë¡œì„¸ìŠ¤ ì„¤ëª…
1. ì‚¬ìš©ìë¡œë¶€í„° ëŒ€í™” ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.
2. ëŒ€í™” ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³ , ê°€ëŠ¥í•œ Speaker ëª©ë¡ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
3. ì‚¬ìš©ìê°€ ëŒ€í™”í•˜ê³  ì‹¶ì€ Speakerë¥¼ ì„ íƒí•˜ë©´, í•´ë‹¹ Speakerì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.
4. ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë¬¸ì¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° ëŒ€í™”ë¥¼ ì°¾ì•„ ì¶œë ¥í•©ë‹ˆë‹¤.
5. Ollama ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬, ì„ íƒí•œ Speakerì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ì— ë§ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
6. ìƒì„±ëœ ì‘ë‹µì„ ì¶œë ¥í•˜ê³ , ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°‘ë‹ˆë‹¤.
"""

def load_chat_data(csv_file_path):
    """CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê°€ëŠ¥í•œ Speaker ëª©ë¡ì„ ë°˜í™˜"""
    df_chat = pd.read_csv(csv_file_path)
    
    if "Speaker" not in df_chat.columns or "Message" not in df_chat.columns:
        raise ValueError("CSV íŒŒì¼ì— 'Speaker' ë° 'Message' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    speakers = df_chat["Speaker"].unique().tolist()
    return df_chat, speakers

def choose_speaker(speakers):
    """ì‚¬ìš©ìê°€ ëŒ€í™”ì—ì„œ íŠ¹ì • Speakerë¥¼ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ í•¨"""
    print("ğŸ“¢ ê°€ëŠ¥í•œ ëŒ€í™” ìƒëŒ€ ëª©ë¡:")
    for i, speaker in enumerate(speakers):
        print(f"{i + 1}. {speaker}")
    
    choice = int(input("ğŸ’¡ ëŒ€í™”í•  ëŒ€ìƒì„ ì„ íƒí•˜ì„¸ìš” (ìˆ«ì ì…ë ¥): ")) - 1
    return speakers[choice]

def analyze_speaker_style(df_chat, speaker):
    """íŠ¹ì • Speakerì˜ ëŒ€í™” íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬, ìì£¼ ì“°ëŠ” ë‹¨ì–´ ë° ë§íˆ¬ ìŠ¤íƒ€ì¼ì„ ì¶”ì¶œ"""
    speaker_messages = df_chat[df_chat["Speaker"] == speaker]["Message"].astype(str)
    
    # ë‹¨ì–´ ë¹ˆë„ìˆ˜ ê³„ì‚°
    word_counts = Counter(" ".join(speaker_messages).split())
    top_words = [word for word, count in word_counts.most_common(10)]
    
    # ê°íƒ„ì‚¬ ë° ë‹¨ì¶•ì–´ íŒ¨í„´ ë¶„ì„
    common_expressions = ["ã…‹ã…‹", "ã…ã…", "ã… ã… ", "ã…‡ã…‡", "ã„·ã„·", "ã„±ã„±", "ã…œã…œ"]
    expression_counts = {exp: sum(1 for msg in speaker_messages if exp in msg) for exp in common_expressions}
    top_expressions = [exp for exp, count in expression_counts.items() if count > 0]
    
    # ë¬¸ì¥ ê¸¸ì´ ë¶„ì„
    avg_length = sum(len(msg) for msg in speaker_messages) / len(speaker_messages)
    style_description = f"{avg_length}" if avg_length < 10 else f"{avg_length}"
    
    return top_words, top_expressions, style_description

def find_similar_message(df_chat, target_speaker, user_input, top_n=3):
    """TF-IDFë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • Speakerì˜ ê³¼ê±° ëŒ€í™” ì¤‘ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ì„ ê²€ìƒ‰"""
    
    # ì„ íƒí•œ Speakerì˜ ëŒ€í™”ë§Œ ì‚¬ìš©
    speaker_messages = df_chat[df_chat["Speaker"] == target_speaker]["Message"].astype(str)

    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(speaker_messages)

    user_tfidf = vectorizer.transform([user_input])
    similarities = cosine_similarity(user_tfidf, tfidf_matrix).flatten()

    # ìœ ì‚¬ë„ê°€ ë†’ì€ ë¬¸ì¥ ìƒìœ„ Nê°œ ì¶”ì¶œ
    top_indices = similarities.argsort()[-top_n:][::-1]
    
    return speaker_messages.iloc[top_indices].tolist()

def generate_response(df_chat, target_speaker, user_input, conversation_history):
    """Ollama ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • Speakerì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ì— ë§ëŠ” ì‘ë‹µ ìƒì„±"""
    
    similar_chats = find_similar_message(df_chat, target_speaker, user_input, top_n=5)
    
    # íŠ¹ì • Speakerì˜ ë§íˆ¬ ë¶„ì„
    top_words, top_expressions, style_description = analyze_speaker_style(df_chat, target_speaker)
    
    recent_conversations = "\n".join(
        [f"{chat['speaker']}: {chat['message']}" for chat in conversation_history[-5:]]
    )
    history_text = " ".join(similar_chats)
    
    prompt = f"""
    ë„ˆëŠ” "{target_speaker}"ì²˜ëŸ¼ ë§í•´ì•¼ í•´.
    "{target_speaker}"ì˜ ëŒ€í™” ìŠ¤íƒ€ì¼ì€ ë‹¤ìŒê³¼ ê°™ì•„:
    - í‰ê· ì ì¸ ë¬¸ì¥ ê¸¸ì´: {style_description}ì (ë„ˆë„ ë¹„ìŠ·í•œ ê¸¸ì´ë¡œ ë‹µë³€í•´)
    - ìì£¼ ì“°ëŠ” ë‹¨ì–´: {", ".join(top_words)}
    - ìì£¼ ì“°ëŠ” í‘œí˜„: {", ".join(top_expressions)}

    ê³¼ê±° ëŒ€í™” ê¸°ë¡ (ì°¸ê³ ìš©):
    {history_text}

    ìµœê·¼ ëŒ€í™”:
    {recent_conversations}

    ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ë‚˜ê°€ë„ë¡ ë‹µë³€ì„ ìƒì„±í•´ì¤˜.
    - ê°™ì€ ë¬¸ì¥ì„ ë°˜ë³µí•˜ì§€ ë§ê³ , ìƒí™©ì— ë”°ë¼ ì ì ˆí•˜ê²Œ ë³€í˜•í•´ì„œ ì‘ë‹µí•´ì¤˜.
    - ë‹¨ìˆœí•œ ì§ˆë¬¸-ì‘ë‹µ í˜•íƒœê°€ ì•„ë‹ˆë¼, ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¡œ ì´ì–´ì§€ë„ë¡ ì‘ë‹µì„ ìƒì„±í•´ì¤˜.
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ëŒ€ë‹µì„ í•˜ë˜, ì´ì „ ëŒ€í™”ì™€ì˜ ì—°ê²°ì„±ì„ ê³ ë ¤í•´.
    - ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ë˜, "{target_speaker}"ì˜ ë§íˆ¬ë¥¼ ìœ ì§€í•´ì•¼ í•´.
    
    ì‚¬ìš©ì: "{user_input}"
    {target_speaker}:
    """
    
    response = ollama.chat(
        model="llama3.1:8b", 
        messages=[
                {"role": "system", "content": "ë„ˆëŠ” ëŒ€í™” ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ë©´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì‘ë‹µí•˜ëŠ” AIì•¼."},
                {"role": "user", "content": prompt}
            ]
        )

    return response["message"]["content"]

while True:
    csv_file_path = input("ğŸ’¡ ëŒ€í™” ë°ì´í„° CSV íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ")
    df_chat, speakers = load_chat_data(csv_file_path)
    
    target_speaker = choose_speaker(speakers)
    conversation_history = []
    
    while True:
        user_input = input("ì‚¬ìš©ì: ")
        response = generate_response(df_chat, target_speaker, user_input, conversation_history)
        
        print(f"{target_speaker}: {response}")
        conversation_history.append({"speaker": "ì‚¬ìš©ì", "message": user_input})
        conversation_history.append({"speaker": target_speaker, "message": response})